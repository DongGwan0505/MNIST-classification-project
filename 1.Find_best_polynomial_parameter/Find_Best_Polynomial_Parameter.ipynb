{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqaljxbaFVIVz59zDXr9xU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DongGwan0505/MNIST-classification-project/blob/main/Find_Best_Polynomial_Parameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMKtFReBSBeB"
      },
      "outputs": [],
      "source": [
        "import sys #시스템 관련 모듈 임포트\n",
        "assert sys.version_info >= (3, 5) #파이썬 버전이 3.5이상인지 확인\n",
        "import sklearn #scikit-learn이라는 머신러닝 라이브러리 임포트\n",
        "assert sklearn.__version__ >= \"0.20\" #버전이 2.0이상인지 확인\n",
        "import numpy as np #Numpy라이브러리 임포트 및 np로 부른다.\n",
        "import os #운영체제 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT_DIR = \".\" #PROJECT_ROOT_DIR 변수에 현재 디렉토리를 지정\n",
        "\n",
        "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"data\")\n",
        "\n",
        "#DATA_PATH 변수에는 PROJECT_ROOT_DIR과 \"data\"라는 폴더를 합친 경로를 할당\n",
        "CHAPTER_ID   = \"training_linear_models\"\n",
        "\n",
        "#\"CHAPTER_ID 변수에는 training_linear_models\"라는 문자열을 할당\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "\n",
        "#IMAGES_PATH 변수에 PROJECT_ROOT_DIR, \"images\" 폴더, CHAPTER_ID를 합친 경로를 할당\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "#IMAGES_PATH에 해당하는 디렉토리를 생성 exist_ok=True는 이미 디렉토리가 존재해도 오류를 발생시키지 않고 넘어간다\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "TNEuLa9TSF_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#그래프를 이미지 파일로 저장하는 함수. fig_id=그래프의 이름, 그리고, 해당 그래프를 이미지 파일로 저장. 저장 경로는 IMAGES_PATH에 fig_id와 확장자를 합친 것. tight_layout 매개변수가 True로 설정되어 있으면 그래프를 저장하기 전에 자동으로 레이아웃을 조정. 그래프는 지정된 확장자와 해상도로 저장\n",
        "os.makedirs(DATA_PATH, exist_ok=True) #DATA_PATH에 해당하는 디렉토리를 생성\n",
        "np.random.seed(25) #Numpy의 랜덤 시드 설정\n",
        "%cd data #현재 작업 디렉토리를 \"data\" 폴더로 변경\n",
        "\n",
        "X = np.load('X_datafile.npy')\n",
        "y = np.load('y_datafile.npy') #저장된 NumPy 배열 데이터를 로드\n",
        "X.shape #X는 300행 1열의 행렬이다."
      ],
      "metadata": {
        "id": "senrZ1ewSJN2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "1d4f876c-8cfd-4865-a0a3-60619fbde8e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'data #현재 작업 디렉토리를 data 폴더로 변경'\n",
            "/content\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'X_datafile.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3643699085.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data #현재 작업 디렉토리를 \"data\" 폴더로 변경'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_datafile.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_datafile.npy'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#저장된 NumPy 배열 데이터를 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;31m#X는 300행 1열의 행렬이다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X_datafile.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mpl.rc('axes', labelsize=14) #축 레이블의 폰트 크기를 14로 설정\n",
        "mpl.rc('xtick', labelsize=12) #x축 눈금 레이블의 폰트 크기를 12로 설정\n",
        "mpl.rc('ytick', labelsize=12) #y축 눈금 레이블의 폰트 크기를 12로 설정\n",
        "\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y', rotation=0)"
      ],
      "metadata": {
        "id": "k3ds_hTQSJP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "#scikit-learn의 PolynomialFeatures를 사용하여 주어진 특성에 다항식 특성을 추가\n",
        "poly_features = PolynomialFeatures (degree=2, include_bias=False)\n",
        "\n",
        "#degree = 다항식의 차수\n",
        "#include_bias=False는 절편(intercept)을 포함할 것인지 여부를 나타낸다.\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "#Polynomial Features (𝑥,𝑥^2) 를 생성 한다"
      ],
      "metadata": {
        "id": "IdBZLxTJSJST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression #scikit-learn에서 선형 회귀 모델을 임포트\n",
        "lin_reg = LinearRegression() #선형 회귀 모델 객체를 생성\n",
        "lin_reg.fit( X_poly, y) # y[i] =  f( X[i], X[i]*X[i] )\n",
        "# 선형 회귀 모델을 주어진 다항 특성이 추가된 데이터 X_poly와 타겟 변수 y에 대해 학습시킨다.\n",
        "lin_reg.intercept_, lin_reg.coef_ #학습된 모델의 절편(intercept),학습된 모델의 계수(coefficient) 값, 즉 특성들의 가중치(weights) 값을 반환\n",
        "X_new = np.linspace(-2, 2, 300).reshape(300, 1)\n",
        "#-2에서 2까지의 범위에서 300개의 데이터 포인트를 생성하고, 300x1의 형태로 재구성하여 X_new에 할당\n",
        "X_new_poly = poly_features.transform( X_new )\n",
        "#새로운 데이터에 대해 다항 특성을 변환하여 X_new_poly에 할당\n",
        "y_new = lin_reg.predict(X_new_poly)\n",
        "#변환된 새로운 데이터에 대해 학습된 모델로 예측을 수행하고, 예측값을 y_new에 할당"
      ],
      "metadata": {
        "id": "CnswccwESJUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(X, y, \"b.\")\n",
        "#원본 데이터인 X와 그에 해당하는 타겟 변수인 y를 파란색 점으로 시각화\n",
        "plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\n",
        "#새로운 데이터 X_new에 대한 예측값인 y_new를 빨간색 실선으로 시각화하고, 선의 두께를 2로 설정합니다. 또한, 이 예측 결과를 나타내는 라벨을 \"Predictions\"으로 지정"
      ],
      "metadata": {
        "id": "yueRCtzNSJWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#<B>\n",
        "from sklearn.metrics import mean_squared_error #에러 값 평가\n",
        "from sklearn.model_selection import train_test_split #데이터를 테스트, 트레이닝으로 나눈다.\n",
        "def plot_learning_curves (model, X, y) :\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "#테스트 사이즈 20% 트레이닝 사이즈 80%\n",
        "    train_errors, val_errors = [], []\n",
        "    for m in range(1, len(X_train)) :\n",
        "        model.fit(X_train[:m], y_train[:m])   # 1개, 2개, n개 instancece로 학습, ...\n",
        "        y_train_predict = model.predict(X_train[:m])\n",
        "        y_val_predict   = model.predict(X_val)\n",
        "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
        "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
        "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
        "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n",
        "    plt.legend(loc=\"upper right\", fontsize=14)\n",
        "    plt.xlabel(\"Training set size\", fontsize=14)\n",
        "    plt.ylabel(\"RMSE\", fontsize=14)\n"
      ],
      "metadata": {
        "id": "Hc5TpdZkd5vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "polynomial_regression = Pipeline([\n",
        "        (\"poly_features\", PolynomialFeatures(degree=1, include_bias=False)),\n",
        "        (\"lin_reg\", LinearRegression()),\n",
        "    ]) #degree를 1~40까지 설정하여 n차 선형 회귀 모델 숫자 1을 1~40까지 설정한다.\n",
        "plt.title(\"the 1st model\") #1차 선형 회귀 모델 숫자 1을 1~40까지 설정한다.\n",
        "plot_learning_curves(polynomial_regression, X, y)\n",
        "plt.axis([0, 80, 0, 3])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VOAvzGNQd9gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#<C>\n",
        "np.random.seed(42) #같은 데이터를 이용해도 랜덤시드가 다르면 plot의 모습이 조금 달라진다.\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:300], y[:300].ravel(), test_size=0.2, random_state=10)\n",
        "#300개의 데이터를 모두 사용하여 테스트 사이즈를 20%로 설정한다.\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "#Stochastic Gradient Descent로 다항 회귀 모델을 훈련\n",
        "poly_scaler = Pipeline([\n",
        "        (\"poly_features\", PolynomialFeatures(degree=3, include_bias=False)),\n",
        "        (\"std_scaler\", StandardScaler()) ])\n",
        "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
        "X_val_poly_scaled = poly_scaler.transform(X_val)\n",
        "sgd_reg = SGDRegressor(max_iter=10, warm_start=True, #iteration을 10으로 설정했다.\n",
        "                       penalty=None, learning_rate=\"constant\", eta0=0.0005, random_state=42)\n",
        "#iteration을 10으로 두었다.\n",
        "from copy import deepcopy\n",
        "minimum_val_error = float(\"inf\")\n",
        "best_epoch = None\n",
        "best_model = None\n",
        "for epoch in range(5000) :\n",
        "    sgd_reg.fit(X_train_poly_scaled, y_train)\n",
        "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
        "    val_error      = mean_squared_error(y_val, y_val_predict)\n",
        "    if val_error < minimum_val_error :\n",
        "        minimum_val_error = val_error\n",
        "        best_epoch = epoch\n",
        "        best_model = deepcopy(sgd_reg)\n",
        "sgd_reg = SGDRegressor(max_iter=10, tol= 1e-3, warm_start=True, #iteration을 10으로 설정했다.\n",
        "                       penalty=None, learning_rate=\"constant\", eta0=0.0005, random_state=42)\n"
      ],
      "metadata": {
        "id": "yPk7yyEYeIWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5000 #epoch를 500으로 설정하였다.\n",
        "train_errors, val_errors = [], []\n",
        "for epoch in range(n_epochs):\n",
        "    sgd_reg.fit(X_train_poly_scaled, y_train)\n",
        "    y_train_predict = sgd_reg.predict(X_train_poly_scaled)\n",
        "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
        "    train_errors.append(mean_squared_error(y_train, y_train_predict))\n",
        "    val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
        "best_epoch = np.argmin(val_errors)\n",
        "best_val_rmse = np.sqrt(val_errors[best_epoch])\n",
        "plt.annotate('Best model',\n",
        "             xy=(best_epoch, best_val_rmse),\n",
        "             xytext=(best_epoch, best_val_rmse + 1),\n",
        "             ha=\"center\",\n",
        "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
        "             fontsize=16,)\n",
        "\n",
        "best_val_rmse -= 0.03  # just to make the graph look better\n"
      ],
      "metadata": {
        "id": "d5VdiQwheKuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([0, n_epochs], [best_val_rmse, best_val_rmse], \"k:\", linewidth=2)\n",
        "plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"Validation set\")\n",
        "plt.plot(np.sqrt(train_errors), \"r--\", linewidth=2, label=\"Training set\")\n",
        "plt.legend(loc=\"upper right\", fontsize=14)\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.ylabel(\"RMSE\", fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GF0jZb4keOCk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
