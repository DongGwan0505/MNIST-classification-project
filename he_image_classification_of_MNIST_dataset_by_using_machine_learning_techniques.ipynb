{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1t6NBHH2D3wVf03JR4Ssg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DongGwan0505/MNIST-classification-project/blob/main/he_image_classification_of_MNIST_dataset_by_using_machine_learning_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYvY0skJIKm1"
      },
      "outputs": [],
      "source": [
        "## 기본설정\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"classification\"\n",
        "IMAGES_PATH = os.path.join( PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs( IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout :\n",
        "        plt.tight_layout()\n",
        "    plt.savefig (path, format=fig_extension, dpi=resolution)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MNIST 데이터 로드\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "# MNIST 데이터셋은 28x28 픽셀의 이미지가 784개의 특성으로 펼쳐져 있기 때문에,\n",
        "70,000개의 이미지가 있다면 X.shape는 (70000, 784)이다\n",
        "\n",
        "y = y.astype(np.uint8)\n",
        "#문자인 y를 8bits의 unsigned int로 변환한다.\n",
        "\n",
        "X = X / 255.0\n",
        "#Pixel=Pixel/255\n",
        "\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
        "#training data와 test data로 분리한다."
      ],
      "metadata": {
        "id": "24fcc6zJKHIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Softmax Regression\n",
        "softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000, C=1.0, random_state=42)\n",
        "softmax_reg.fit(X_train, y_train)\n",
        "#일단 C=1로 설정한 후 진행해보았다.\n",
        "softmax_reg.predict([X_train[0]])\n",
        "\n",
        "softmax_reg.predict_proba([X_train[0]])\n",
        "\n",
        "y = y.astype(np.uint8)\n",
        "X = X / 255.0\n",
        "#위는 이전 코드와 동일하다.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X.astype(np.float64))\n",
        "#데이터 X에 대해 standard scaler를 적용하고 train data와 test data로 나누었다.\n",
        "X_train, X_test, y_train, y_test = X_scaled[:60000], X_scaled[60000:], y[:60000], y[60000:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Rt1-TuHZKPmN",
        "outputId": "f9802b79-dcb1-4d53-c612-35fddb01d4d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LogisticRegression' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-677995057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Softmax Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msoftmax_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multinomial\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msoftmax_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#일단 C=1로 설정한 후 진행해보았다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msoftmax_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SVM (suppott vector machine)\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 스케일링 및 PCA\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# PCA를 적용하여 데이터 차원 축소, 설명된 분산의 95%를 유지하도록 설정\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# 모델 훈련\n",
        "svm_clf = SVC(kernel='rbf', C=1, gamma=0.001)\n",
        "svm_clf.fit(X_train_pca, y_train)\n",
        "# 성능 평가\n",
        "y_pred = svm_clf.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"테스트 세트 정확도: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "7TkRzqhBKWzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Random Forrest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf_clf = RandomForestClassifier\n",
        "(max_features=\"sqrt\", max_samples=None, max_depth=None, n_estimators=20, random_state=42)\n",
        "# max_features=\"sqrt\", max_samples=None, max_depth=None로 설정했다.\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "rCtS42qyKmTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}